---
title: "Using spaCy v2.1 with spacyr"
author: "Akitaka Matsuo"
date: '2019-03-28'
tags: ["blog"]
blogdown::html_page:
  highlight: tango
---



<p>A major update of <a href="https://spacy.io"><strong>spaCy</strong></a> (v2.1) was <a href="https://github.com/explosion/spaCy/releases/tag/v2.1.0">released</a> recently. <strong>spaCy</strong> is one of the best and fastest tools for tokenization, part-of-speech tagging, dependency parsing, and entity recognition. In this post, I will discuss how it works with our <a href="https://spacyr.quanteda.io"><strong>spacyr</strong></a> package along with some tips on having multiple versions of <strong>spaCy</strong> using conda environments.</p>
<div id="good-news-it-works" class="section level2">
<h2>Good news: It works</h2>
<p>Our package <strong>spacyr</strong> is an R wrapper to the <strong>spaCy</strong> Python library. To work with the <strong>spacyr</strong> package, users have to prepare a Python environment with <strong>spaCy</strong> installed. This may not be difficult if you are familiar with both R and Python, but that may not be necessarily the case for R-only users. To help such users, we implemented a function called <code>spacy_install()</code> which provides a one-step solution.</p>
<p>The gist of what the function does is:</p>
<ol style="list-style-type: decimal">
<li>Create a new conda environment (with new Python executable)</li>
<li>pip-install spacy in the new environment</li>
</ol>
<p>The implementation of the function owes a lot to a similar function in the <a href="https://www.tensorflow.org"><strong>tensorflow</strong></a> package. If everything works as intended, the installation process is truly one-step. And for Mac and Linux users, <code>spacy_install()</code> even downloads <a href="https://docs.conda.io/en/latest/miniconda.html">Miniconda</a> when it does not exist in the system. This seems to be working for most cases. However, as you can see from the <a href="https://github.com/quanteda/spacyr/issues?utf8=%E2%9C%93&amp;q=is%3Aissue">issues</a> in our GitHub repository, some users have troubles in installing it (see for example <a href="https://github.com/quanteda/spacyr/issues/156">this</a> issue). Typically, the problem is caused by not having installed a C++ compiler, as some operating systems (pretty much all except Linux) do not include one by default.</p>
<p>Assuming that you have an old <strong>spaCy</strong> installed through <strong>spacyr</strong>, you can try updating to the new <strong>spaCy</strong> by our other function:</p>
<pre class="r"><code>spacy_upgrade()</code></pre>
<p>In my environment (Mac OS Mojave), it did not work and the installation stopped in the middle. The error was fixable<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>, but it requires some work in console and does not fit to the purpose of our one-step solution through <code>spacy_install()</code>.</p>
<p>So I decided to use an easy solution (which I recoomend if you experience the same issue): Delete the current conda environment and re-install</p>
<pre class="r"><code>spacy_uninstall() 
spacy_install()</code></pre>
<p>Once we did this on macOS, everything worked fine:</p>
<pre class="r"><code>library(spacyr)
spacy_initialize(model = &quot;en&quot;)
## spacy python option is already set, spacyr will use:
##  condaenv = &quot;spacy_condaenv&quot;
## successfully initialized (spaCy Version: 2.1.3, language model: en)
## (python options: type = &quot;condaenv&quot;, value = &quot;spacy_condaenv&quot;)
spacy_parse(&quot;hello world&quot;)
##   doc_id sentence_id token_id token lemma  pos entity
## 1  text1           1        1 hello hello INTJ       
## 2  text1           1        2 world world NOUN</code></pre>
<p>If you have your original environment (e.g. a custom language model you trained) and do not want to mess up the setup, you can test a new version by creating another environment as described below.</p>
</div>
<div id="another-good-news-tokenization-is-faster-and-you-can-feel-it-in-spacyr" class="section level2">
<h2>Another good news: Tokenization is faster and you can feel it in spacyr</h2>
<p>The tokenization is really fast in <strong>spaCy</strong> v2.1. That can be seen from <code>spacy_tokenize()</code>. The benchmark comparison looks like this:</p>
<pre><code>## Unit: milliseconds
##     expr       min        lq      mean    median        uq       max neval
##   v2.1.3  134.6249  143.3171  149.7733  151.7219  155.2604  163.8899    10
##  v2.0.18 1472.2077 1487.7420 1536.3897 1496.1156 1523.6667 1869.4669    10</code></pre>
<p>This is based on tokenizing a fairly small corpus of 14 documents containing a total of about 54,000 words (the <code>quanteda::data_corpus_irishbudget2010</code> corpus). Due to the impossiblity of unloading Python (see the last section of this post), each benchmark had to be run in a separate R session and combined afterwards. (See this <a href="https://gist.github.com/amatsuo/7f64299310a110bd8158e3c2b262ff0b">gist</a> for details.)</p>
<p>The difference is massive: <strong>spaCy</strong> v2.1 is about <strong>10 (!) times faster</strong> in tokenization called from <strong>spacyr</strong>.</p>
<p>So this is great. However, there is a caveat in this performance gain. <strong><code>spacy_tokenize()</code> is fast under limited conditions.</strong> By default, <strong>spaCy</strong> has <a href="https://spacy.io/usage/processing-pipelines">four pipeline components</a>: <code>tokenizer</code>, <code>tagger</code>, <code>parser</code> and <code>ner</code>. In version v2.1, the tokenizer became really, really fast. So, if you run only <code>tokenizer</code>, which is the first component of the pipeline (i.e. run <code>spacy_tokenize()</code> with all default options), it is very fast. However, if you need to conduct more feature rich tokenization (e.g. <code>spacy_tokenize(remove_numbers = TRUE)</code>), the later components of the pipeline have to be run and it will take longer to finish.</p>
<pre class="r"><code>data_text_irishbudget2010 &lt;- quanteda::texts(quanteda::data_corpus_irishbudget2010)
microbenchmark::microbenchmark(
    &quot;remove_numbers = TRUE&quot; = spacy_tokenize(data_text_irishbudget2010, remove_numbers = TRUE),
    &quot;remove_numbers = FALSE&quot; = spacy_tokenize(data_text_irishbudget2010),
    times = 1
)
## Unit: milliseconds
##                    expr       min        lq      mean    median        uq
##   remove_numbers = TRUE 7369.6198 7369.6198 7369.6198 7369.6198 7369.6198
##  remove_numbers = FALSE  131.2638  131.2638  131.2638  131.2638  131.2638
##        max neval
##  7369.6198     1
##   131.2638     1</code></pre>
<p>(I didn’t check whether or not this slowdown is caused by our code in either R or Python. We will test this more thoroughly in the future.)</p>
</div>
<div id="a-note-on-having-multiple-versions-of-spacy-in-your-spacyr-installation" class="section level2">
<h2>A note on having multiple versions of spaCy in your spacyr installation</h2>
<p>The current setup of <code>spacy_install()</code> creates a new conda environment isolated from other environments, and thus, if you want to have multiple versions of <strong>spaCy</strong>, this is easily possible.</p>
<p>One thing to remember for doing that is <strong>you need to restart R when switching from one spaCy to another</strong>. That is because of the difficulty of unloading the Python environment. In the backend, we use the wonderful <a href="https://github.com/rstudio/reticulate/"><strong>reticulate</strong></a> package by RStudio for seamless integration of R with Python. The developer of the package <a href="https://github.com/rstudio/reticulate/issues/27#issuecomment-288728371">has made it clear</a> that unloading Python is technically difficult and reticulate does not support that.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>Having said that, here is the way to install two versions of spaCy:</p>
<pre class="r"><code>library(spacyr)

## install the latest version of spaCy (will be installed in &quot;spacy_condaenv&quot;)
spacy_install()

## install an older version of spaCy (in an enviroment &quot;spacy_old&quot;)
spacy_install(version = &quot;2.0.18&quot;, envname = &quot;spacy_old&quot;)</code></pre>
<p>To use these environments, you can specify the version when you call <code>spacy_initialize()</code>.</p>
<pre class="r"><code>## to use latest version
spacy_initialize(refresh_settings = TRUE)

## to use the older version
spacy_initialize(condaenv = &quot;spacy_old&quot;, refresh_settings = TRUE)</code></pre>
<p>The first line <code>spacy_initialize(refresh_settings = TRUE)</code> will use <code>spacy_condaenv</code> as that’s the first thing <strong>spacyr</strong> will check when initializing <strong>spaCy</strong>. <strong>spacyr</strong> searches possible locations of <strong>spaCy</strong> installation when <code>spacy_initialize()</code> is called for the first time (not in this session, but in the entire history). After successfully initializing <strong>spaCy</strong>, <strong>spacyr</strong> will remember the location and use the same setting thereafter. Now that you are switching between two environments, you need to have <strong>spacyr</strong> ignoring the saved setting. <code>refresh_settings = TRUE</code> in <code>spacy_initialize()</code> will do the job.</p>
</div>
<div id="summary" class="section level2">
<h2>Summary</h2>
<p>In this post, I have discussed a few features of <strong>spacyr</strong> related to the new release of <strong>spaCy</strong>. In summary:</p>
<ol style="list-style-type: decimal">
<li><strong>spaCy</strong> v2.1 works with <strong>spacyr</strong>;</li>
<li><strong>spaCy</strong> tokenization is much faster in v2.1 than the tokenization in previous versions; and</li>
<li><strong>spacyr</strong> can help you to set up multiple Python environments.</li>
</ol>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>The error message I got was: <em>ImportError: Something is wrong with the numpy installation. While importing we detected an older version of numpy in [‘…/anaconda/envs/spacy_condaenv/lib/python3.6/site-packages/numpy’]. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version.</em><a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>spacyr has a function called <code>spacy_finalize()</code>. This function deletes all objects created by <strong>spaCy</strong> in the Python space but does not delete the Python space itself.<a href="#fnref2" class="footnote-back">↩</a></p></li>
</ol>
</div>
